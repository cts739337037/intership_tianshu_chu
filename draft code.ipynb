{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GSPC.set_index(pd.to_datetime(GSPC['Date']), inplace=True)#Set the index of the DataFrame to make it become date type.\n",
    "del GSPC['Date']\n",
    "GSPC=GSPC.T\n",
    "GSPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44740c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m pip install h5py\n",
    "from __future__ import print_function  \n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility  用于指定随机数生成时所用算法开始的整数值，如果使用相同的seed()值，则每次生成的随即数都相同\n",
    "  \n",
    "from PIL import Image  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD  \n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "'''\n",
    "Olivetti Faces是纽约大学的一个比较小的人脸库，由40个人的400张图片构成，即每个人的人脸图片为10张。每张图片的灰度级为8位，每个像素的灰度大小位于0-255之间。整张图片大小是1190 × 942，一共有20 × 20张照片。那么每张照片的大小就是（1190 / 20）× （942 / 20）= 57 × 47 。\n",
    "'''\n",
    "\n",
    "# There are 40 different classes  \n",
    "nb_classes = 40  # 40个类别\n",
    "epochs = 40  # 进行40轮次训\n",
    "batch_size = 40 # 每次迭代训练使用40个样本\n",
    "  \n",
    "# input image dimensions  \n",
    "img_rows, img_cols = 57, 47  \n",
    "# number of convolutional filters to use  \n",
    "nb_filters1, nb_filters2 = 5, 10  # 卷积核的数目（即输出的维度）\n",
    "# size of pooling area for max pooling  \n",
    "nb_pool = 2  \n",
    "# convolution kernel size  \n",
    "nb_conv = 3  # 单个整数或由两个整数构成的list/tuple，卷积核的宽度和长度。如为单个整数，则表示在各个空间维度的相同长度。\n",
    "  \n",
    "def load_data(dataset_path):  \n",
    "    img = Image.open(dataset_path)  \n",
    "    img_ndarray = np.asarray(img, dtype = 'float64') / 255  # asarray，将数据转化为np.ndarray，但使用原内存\n",
    "    # 400 pictures, size: 57*47 = 2679  \n",
    "    faces = np.empty((400, 2679)) \n",
    "    for row in range(20):  \n",
    "        for column in range(20):\n",
    "           faces[row * 20 + column] = np.ndarray.flatten(img_ndarray[row*57 : (row+1)*57, column*47 : (column+1)*47]) \n",
    "           # flatten将多维数组降为一维\n",
    "  \n",
    "    label = np.empty(400)  \n",
    "    for i in range(40):\n",
    "        label[i*10 : i*10+10] = i  \n",
    "    label = label.astype(np.int)  \n",
    "  \n",
    "    #train:320,valid:40,test:40  \n",
    "    train_data = np.empty((320, 2679))  \n",
    "    train_label = np.empty(320)  \n",
    "    valid_data = np.empty((40, 2679))  \n",
    "    valid_label = np.empty(40)  \n",
    "    test_data = np.empty((40, 2679))  \n",
    "    test_label = np.empty(40)  \n",
    "  \n",
    "    for i in range(40):\n",
    "        train_data[i*8 : i*8+8] = faces[i*10 : i*10+8] # 训练集中的数据\n",
    "        train_label[i*8 : i*8+8] = label[i*10 : i*10+8]  # 训练集对应的标签\n",
    "        valid_data[i] = faces[i*10+8] # 验证集中的数据\n",
    "        valid_label[i] = label[i*10+8] # 验证集对应的标签\n",
    "        test_data[i] = faces[i*10+9] \n",
    "        test_label[i] = label[i*10+9]   \n",
    "    \n",
    "    train_data = train_data.astype('float32')\n",
    "    valid_data = valid_data.astype('float32')\n",
    "    test_data = test_data.astype('float32')\n",
    "       \n",
    "    rval = [(train_data, train_label), (valid_data, valid_label), (test_data, test_label)]  \n",
    "    return rval  \n",
    "  \n",
    "def set_model(lr=0.005,decay=1e-6,momentum=0.9): \n",
    "    model = Sequential()\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        model.add(Conv2D(5, kernel_size=(3, 3), input_shape = (1, img_rows, img_cols)))\n",
    "    else:\n",
    "        model.add(Conv2D(5, kernel_size=(3, 3), input_shape = (img_rows, img_cols, 1)))\n",
    "    model.add(Activation('relu')) #sigmoid，relu，tanh，elu\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    model.add(Conv2D(10, kernel_size=(3, 3)))  \n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "    model.add(Dropout(0.25))  \n",
    "    model.add(Flatten())      \n",
    "    model.add(Dense(128)) #Full connection  \n",
    "    model.add(Activation('tanh')) \n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(nb_classes))  \n",
    "    model.add(Activation('softmax'))  \n",
    "    sgd = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)  \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)#keras.losses.binary_crossentropy  'categorical_crossentropy'\n",
    "    return model  \n",
    "  \n",
    "def train_model(model,X_train, Y_train, X_val, Y_val):  \n",
    "    model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,  \n",
    "          verbose=1, validation_data=(X_val, Y_val))  \n",
    "    model.save_weights('model_weights.h5', overwrite=True)  \n",
    "    return model  \n",
    "  \n",
    "def test_model(model,X,Y):  \n",
    "    model.load_weights('model_weights.h5')  \n",
    "    score = model.evaluate(X, Y, verbose=0)\n",
    "    return score  \n",
    "  \n",
    "if __name__ == '__main__':  \n",
    "    # the data, shuffled and split between tran and test sets  \n",
    "    (X_train, y_train), (X_val, y_val),(X_test, y_test) = load_data('olivettifaces.gif')  \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)  \n",
    "        X_val = X_val.reshape(X_val.shape[0], 1, img_rows, img_cols)  \n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)  \n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)  \n",
    "        X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)  \n",
    "        X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)  \n",
    "        input_shape = (img_rows, img_cols, 1) # 1 为图像像素深度\n",
    "    \n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples') \n",
    "    print(X_val.shape[0], 'validate samples')  \n",
    "    print(X_test.shape[0], 'test samples')\n",
    "  \n",
    "    # convert class vectors to binary class matrices  \n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)  \n",
    "    Y_val = np_utils.to_categorical(y_val, nb_classes)  \n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)  \n",
    "  \n",
    "    model = set_model()\n",
    "    train_model(model, X_train, Y_train, X_val, Y_val)   \n",
    "    score = test_model(model, X_test, Y_test)  \n",
    "  \n",
    "    model.load_weights('model_weights.h5')  \n",
    "    classes = model.predict_classes(X_test, verbose=0)  \n",
    "    test_accuracy = np.mean(np.equal(y_test, classes))  \n",
    "    print(\"accuarcy:\", test_accuracy)\n",
    "    for i in range(0,40):\n",
    "        if y_test[i] != classes[i]:\n",
    "            print(y_test[i], '被错误分成', classes[i]);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4370ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "test_mm = mm.fit_transform(GSPC_test)\n",
    "Y_test_inv=mm.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val[0].shape\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(Y_val_df.apply(lambda x: x.sum()/15,axis=0),\"r\")\n",
    "plt.plot(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab9309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf99f643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
